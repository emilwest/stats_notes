---
title: "Trash image recognition experiments"
subtitle: "Exploring VGG16 convolutional base"
author: Emil Westin
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  word_document: default
  html_notebook: default
---


## Available trash datasets

- [Trashnet](https://github.com/garythung/trashnet)
- [Trash Annotations in Context](http://tacodataset.org/) : currently 1500 images with 4784 annotations 


## Data

I have downloaded from [Trashnet](https://github.com/garythung/trashnet) containing 2527 images of six classes: glass, paper, cardboard, plastic, metal, and trash. 

- 501 glass
- 594 paper
- 403 cardboard
- 482 plastic
- 410 metal
- 137 trash


### Libraries used

```{r ,echo=T , warning=FALSE, message=F}
#tensorflow::install_tensorflow(extra_packages='pillow')
library(keras)
library(tensorflow)
library(tidyverse)
```

\newpage

### Importing data:


```{r}
getwd()
setwd(dir = "C:/Users/emiwes/Desktop")
base_dir <- "C:/Users/emiwes/Downloads/dataset-resized/dataset-resized"
fnames <- list.files(base_dir, full.names = TRUE,recursive = T,include.dirs = F)
n <- fnames %>% length()
```

### Image preprocessing in keras

The images are stored as tensors of shape (samples, height, width, color_depth).
In this case (n, 150, 150, 3), i.e. 3 colors. 

Consider the following example:

```{r ,warning=F}
# load the first file name (cardboard1.jpg) with size 150x150 pixels
tt <- image_load(fnames[1], target_size = c(150, 150) )
tt
```

We can convert it to array as follows:

```{r}
tt2 <- image_to_array(tt)
# 150 x 150 x 3 
dim(tt2)
# shows 3 color values for pixel (1,1):
tt2[1,1,]
```

\newpage

Neural networks prefer to deal with small input numbers. 
As such, it is typical to rescale the pixel values to a [0,1] interval by dividing the pixels by 255.
The array_reshape function does this and says to have the same dimension as before (150, 150, 3):

```{r}
tt3 <- array_reshape(tt2/255, c(150, 150, 3))
dim(tt3)
tt3[1,1,]
```

In general, we can do this procedure for a large number of pictures.

```{r, eval = FALSE}
data <- array(0, c(n,150,150,3))
for(i in 1:n){
    img_path <- fnames[[i]]
    # Convert it to an array with shape (150, 150, 3)
    img <- image_load(img_path, target_size = c(150, 150))
    img_array <- image_to_array(img)
    data[i,,,] <- array_reshape(img_array/255, c(150, 150, 3))
}
# it is a good idea to save this since it can take some time to run:
# save(data, file="img_arr.RData")
```

After running the code above and saving, the data can be re-loaded as:

```{r}
# LOADS THE DATA FILE WITH ThE IMAGE ARRAYS
load(file = "C:/Users/emiwes/Desktop/img_arr.RData")
```

\newpage

We can plot any image from the tensor like this:
```{r}
plot(as.raster(data[1,,,]))
```


## Split data into train/test/validation

```{r}
#labs <- gsub("(.*)/([a-z0-9]+.jpg)", "\\2", fnames) # only filename
labs <- gsub(".*/([a-z]+/[a-z0-9]+.jpg)", "\\1", fnames) # including directory
labs <- as_tibble(labs)
labs %>% head() # this contains the names of the files
```
```{r}
class_name <-  gsub("(.*)/([a-z]+)([0-9]+).jpg", "\\2", fnames) 

labs$class_name <- class_name
labs$class_name <- factor(labs$class_name)

binarized <- model.matrix( value ~ 0 + ., data = labs, contrasts.arg = list(contrasts=F) )
labs <- cbind(id=labs$value, as_tibble(binarized)) 

colnames(labs) <- gsub("class_name","", colnames(labs) )
labs %>% head(5)
```

<!-- https://vijayabhaskar96.medium.com/multi-label-image-classification-tutorial-with-keras-imagedatagenerator-cd541f8eaf24 -->


Lets say we split the data into 60% training and 40% testing.

```{r}
# set.seed(40)
# smp_size <- floor(0.6 * n )
# train_ind <- sample(seq_len(n), size = smp_size)
# 
# train_images <- data[train_ind,,,]
# test_images <- data[-train_ind,,,]
# 
# train_labels <- labs[train_ind,]
# test_labels <- labs[-train_ind,]
# train_labels <- labs[train_ind]
# 
# dim(train_labels)[1] + dim(test_labels)[1] == n
# dim(train_images)
# nrow()
```

***

\newpage

## Import images with flow_images 


```{r}
set.seed(40)
smp_size <- floor(0.6 * n )
train_ind <- sample(seq_len(n), size = smp_size)
train_labels <- labs[train_ind,]

length(train_ind)
test_val_indices <- which( !( seq_len(n) %in%  train_ind  ) )
length(train_ind) + length(test_val_indices) == n


# split half of remaining indices into test and validation
tmp <- labs[test_val_indices,]
smp_size <- floor(0.5 * nrow(tmp) )


set.seed(40)
ind <- sample( test_val_indices , size = smp_size)
test_labels <- tmp[ind,]
val_labels <- tmp[which( !(test_val_indices %in% ind) ), ]

test_labels <- tmp[ind,]
val_labels <- tmp[-ind, ]
val_labels
test_labels
nrow
length(ind)
smp_size
length(train_ind) + smp_size == n
505+813



nrow(val_labels) + nrow(test_labels) + nrow(train_labels) == n
which(tmp[-ind,])
dim(train_labels)

which( !(c(train_ind, ind) %in% seq_len(n) ))

c(train_ind, ind) %>% sort()

train_images <- data[train_ind,,,]
test_images <- data[ind,,,]
validation_images <- data[-ind,,,]
```

\newpage

```{r}
# try only one first
train_labels <- train_labels[,c(1,2)]
test_labels <- test_labels[,c(1,2)]
val_labels <- val_labels[,c(1,2)]

```



```{r}
train_generator <- flow_images_from_data(
  x=array_reshape(training[,,,],c(1600,150,150,3)),
  y=training.labels,
  generator = datagen,
  batch_size = 30,
  shuffle=F
)

###preparing validation data(validation data shouldn't be augmented)
validation_generator <- flow_images_from_data(
  x=array_reshape(validation[,,,],c(400,150,150,3)),
  y=validation.labels,
  batch_size = 30
)

```





```{r}
#paste0(base_dir, "/", gsub("([a-z+])/[a-z0-9]+.jpg", "\\1" , train_labels$id )) %>% view()
#?flow_images_from_dataframe
# https://www.kaggle.com/product-feedback/141059
train_datagen <- image_data_generator(rescale = 1/255) 
validation_datagen <- image_data_generator(rescale = 1/255)
test_datagen <- image_data_generator(rescale = 1/255)

train_generator <- flow_images_from_dataframe(
  directory = base_dir,
  dataframe = train_labels,
  generator = train_datagen,
  x_col = "id",
  y_col = train_labels$cardboard ,
  seed = 40,
  shuffle = TRUE,
  class_mode = "categorical"
)

test_generator <- flow_images_from_dataframe(
  directory = base_dir,
  dataframe = test_labels,
  generator = test_datagen,
  x_col = "id",
  y_col = "cardboard" ,
  seed = 40,
  shuffle = TRUE,
  class_mode = "categorical"
)

validation_generator <- flow_images_from_dataframe(
  directory = base_dir,
  dataframe = val_labels,
  generator = validation_datagen,
  x_col = "id",
  y_col = "cardboard" ,
  seed = 40,
  shuffle = TRUE,
  class_mode = "categorical"
)

# 
# train_generator <- flow_images_from_dataframe(
#   directory = base_dir,
#   dataframe = train_labels,
#   generator = train_datagen,
#   x_col = "id",
#   y_col = list("cardboard","glass","metal","paper","plastic","trash") ,
#   seed = 40,
#   shuffle = TRUE,
#   class_mode = "other"
# )
# 
# test_generator <- flow_images_from_dataframe(
#   directory = base_dir,
#   dataframe = test_labels,
#   generator = test_datagen,
#   x_col = "id",
#   y_col = list("cardboard","glass","metal","paper","plastic","trash") ,
#   seed = 40,
#   shuffle = TRUE,
#   class_mode = "other"
# )
# 
# validation_generator <- flow_images_from_dataframe(
#   directory = base_dir,
#   dataframe = val_labels,
#   generator = validation_datagen,
#   x_col = "id",
#   y_col = list("cardboard","glass","metal","paper","plastic","trash") ,
#   seed = 40,
#   shuffle = TRUE,
#   class_mode = "other"
# )


```


\newpage
```{r}
k <- c(3,3)
model <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32, kernel_size = k, activation = "relu", input_shape = c(150,150,3) ) %>%
  layer_max_pooling_2d(pool_size = c(6,6)) %>%
  layer_conv_2d(filters = 64, kernel_size = k, activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(6,6)) %>%
  layer_conv_2d(filters = 128, kernel_size = k, activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(6,6)) %>%
  layer_conv_2d(filters = 24, kernel_size = k, activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(6,6)) %>%
  layer_flatten() %>% 
  #layer_dense(units = 512, activation = "relu") %>%
  layer_dense(units = 24, activation = "softmax")
  
```

```{r}
summary(model)
```

Compilation step:

```{r}
#?compile
model %>%
  compile(
    loss = 'categorical_crossentropy',
    optimizer = optimizer_rmsprop(lr = 1e-4),
    metrics = c('accuracy')
  )
```

Fitting the model:

```{r}
# https://www.javaer101.com/en/article/24494572.html
history <- model %>%
  fit_generator(  train_generator,
                  steps_per_epoch = 10,
                  epochs = 10,
                  validation_data = validation_generator,
                  validation_steps = 10 )

```



```{r}
conv_base <- application_vgg16(
  weights = "imagenet",
  include_top = FALSE,
  input_shape = c(150, 150, 3)
)
freeze_weights(conv_base)

```


```{r}

model.baseline <- keras_model_sequential() %>%
  conv_base %>%
  layer_flatten() %>%
  layer_dense(units = 20, activation = "relu") %>%
  layer_dense(units = 6, activation = "softmax")

model.baseline %>% compile(
  optimizer = "rmsprop",
  loss = "categorical_crossentropy",
  metrics = c("accuracy")
)

not.augment <- 
  model.baseline %>% fit(
  x=training,
  y=training.labels,
  validation_data=list(validation,validation.labels),
  epochs = 50,
  batch_size = 100,
  workers=16
)

not.augment <- model.baseline %>%
 fit_generator(  train_generator,
                  steps_per_epoch = 10,
                  epochs = 10,
                  validation_data = validation_generator,
                  validation_steps = 10 )

plot(not.augment)

```


